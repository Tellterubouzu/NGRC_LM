/work/gp36/b20072/.bashrc: line 7: /work/gp36/b20072/.cargo/env: No such file or directory
/work/gp36/b20072/.bashrc: line 10: rbenv: command not found
/work/gp36/b20072/.bash_profile: line 9: /work/gp36/b20072/.cargo/env: No such file or directory
Repo card metadata block was not found. Setting CardData to empty.
wandb: Currently logged in as: shimomura-teruki174 (telutelu) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
wandb: setting up run 4r9ewop2
wandb: Tracking run with wandb version 0.23.1
wandb: Run data is saved locally in /work/gp36/b20072/NGRC_LM/src/wandb/run-20251222_102518-4r9ewop2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run NGRC_LM(113.51M_10BT_lr5e-4_d2048_poly1_bs198)3
wandb: ‚≠êÔ∏è View project at https://wandb.ai/telutelu/NGRC_LanguageModel
wandb: üöÄ View run at https://wandb.ai/telutelu/NGRC_LanguageModel/runs/4r9ewop2
Namespace(local_rank=0, deepspeed_config='ds_config.json', use_deepspeed=False, local_batch_size=192, use_gpu_amount=1, learning_rate=0.0005, validate_every_steps=200, save_checkpoint_every_steps=200, generate_every=1000, seq_len=512, total_tokens=10000000000.0, epochs=1, grad_clip_norm=0.0, beta1=0.9, beta2=0.95, weight_decay=0.1, tokenizer_path='meta-llama/Llama-2-7b-hf', ngrc_d_model=2048, ngrc_lag=10, ngrc_poly_degree=1, ngrc_max_cross_terms=256, ngrc_readout_rank=512, ngrc_embed_frozen=False, ngrc_training='sgd', ngrc_loss='ce', ngrc_ridge_alpha=0.001, ngrc_ridge_max_batches=200, dataset_path='HuggingFaceFW/fineweb-edu', val_dataset_path='vesteinn/babylm', wandb_project='NGRC_LanguageModel', wandb_run_name='NGRC_LM(113.51M_10BT_lr5e-4_d2048_poly1_bs198)3', api_file='api.txt', log_grad=False, hf_repo=None, hf_private=True, enable_compile=False)
NGRC_LM initialized: vocab=32000, d_model=2048, lag=10, poly_degree=1, phi_dim=20737, readout_rank=512, embed_trainable=True, loss_type=ce
parameter count: 92.54M
[data] HF streaming dataset HuggingFaceFW/fineweb-edu
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
Repo card metadata block was not found. Setting CardData to empty.
[log] train loss: 8.314319610595703, step: 500, tokens_seen_global: 49152000, tokens_per_sec_global: 559820.7171038107, max_mem_mb: 47064.89088
[log] train loss: 6.864752769470215, step: 1000, tokens_seen_global: 98304000, tokens_per_sec_global: 571946.5039624423, max_mem_mb: 47064.89088
[log] train loss: 6.331720352172852, step: 1500, tokens_seen_global: 147456000, tokens_per_sec_global: 575730.7720320239, max_mem_mb: 47064.891904
[log] train loss: 6.11877965927124, step: 2000, tokens_seen_global: 196608000, tokens_per_sec_global: 577928.921019121, max_mem_mb: 47064.891904
[log] train loss: 5.885381698608398, step: 2500, tokens_seen_global: 245760000, tokens_per_sec_global: 579040.8395541334, max_mem_mb: 47064.891904
[log] train loss: 5.704429626464844, step: 3000, tokens_seen_global: 294912000, tokens_per_sec_global: 579829.6920912982, max_mem_mb: 47064.891904
[log] train loss: 5.62045431137085, step: 3500, tokens_seen_global: 344064000, tokens_per_sec_global: 580324.5303363496, max_mem_mb: 47064.891904
[log] train loss: 5.604882717132568, step: 4000, tokens_seen_global: 393216000, tokens_per_sec_global: 580684.7972754252, max_mem_mb: 47064.891904
[log] train loss: 5.505432605743408, step: 4500, tokens_seen_global: 442368000, tokens_per_sec_global: 580997.5978542425, max_mem_mb: 47064.891904
[log] train loss: 5.2474260330200195, step: 5000, tokens_seen_global: 491520000, tokens_per_sec_global: 581343.0635096788, max_mem_mb: 47064.891904
[log] train loss: 5.291487693786621, step: 5500, tokens_seen_global: 540672000, tokens_per_sec_global: 581560.7777265838, max_mem_mb: 47064.891904
[log] train loss: 5.393279552459717, step: 6000, tokens_seen_global: 589824000, tokens_per_sec_global: 581803.8288976217, max_mem_mb: 47064.891904
[log] train loss: 5.099008560180664, step: 6500, tokens_seen_global: 638976000, tokens_per_sec_global: 581951.0710254166, max_mem_mb: 47064.891904
[log] train loss: 5.112085342407227, step: 7000, tokens_seen_global: 688128000, tokens_per_sec_global: 582118.5273163316, max_mem_mb: 47064.891904
[log] train loss: 5.109319686889648, step: 7500, tokens_seen_global: 737280000, tokens_per_sec_global: 582139.0194594739, max_mem_mb: 47064.891904
[log] train loss: 5.090516090393066, step: 8000, tokens_seen_global: 786432000, tokens_per_sec_global: 582269.3101167122, max_mem_mb: 47064.891904
[log] train loss: 5.1234846115112305, step: 8500, tokens_seen_global: 835584000, tokens_per_sec_global: 582324.8815052424, max_mem_mb: 47064.891904
[log] train loss: 5.117876052856445, step: 9000, tokens_seen_global: 884736000, tokens_per_sec_global: 582412.9018741775, max_mem_mb: 47064.891904
[log] train loss: 5.019270896911621, step: 9500, tokens_seen_global: 933888000, tokens_per_sec_global: 582467.5277939499, max_mem_mb: 47064.891904
[log] train loss: 4.924304485321045, step: 10000, tokens_seen_global: 983040000, tokens_per_sec_global: 582554.9118813542, max_mem_mb: 47064.891904
[log] train loss: 5.1703009605407715, step: 10500, tokens_seen_global: 1032192000, tokens_per_sec_global: 582599.8139627618, max_mem_mb: 47064.891904
[log] train loss: 4.940805435180664, step: 11000, tokens_seen_global: 1081344000, tokens_per_sec_global: 582664.6087221606, max_mem_mb: 47064.891904
[log] train loss: 4.9260101318359375, step: 11500, tokens_seen_global: 1130496000, tokens_per_sec_global: 582699.7064023751, max_mem_mb: 47064.891904
[log] train loss: 5.047841548919678, step: 12000, tokens_seen_global: 1179648000, tokens_per_sec_global: 582744.7935308459, max_mem_mb: 47064.891904
[log] train loss: 4.988853931427002, step: 12500, tokens_seen_global: 1228800000, tokens_per_sec_global: 582760.359710325, max_mem_mb: 47064.891904
[log] train loss: 4.9651923179626465, step: 13000, tokens_seen_global: 1277952000, tokens_per_sec_global: 582794.0719877448, max_mem_mb: 47064.891904
[log] train loss: 4.9772419929504395, step: 13500, tokens_seen_global: 1327104000, tokens_per_sec_global: 582817.9248429913, max_mem_mb: 47064.891904
[log] train loss: 4.903105735778809, step: 14000, tokens_seen_global: 1376256000, tokens_per_sec_global: 582844.4458367213, max_mem_mb: 47064.891904
[log] train loss: 4.9816460609436035, step: 14500, tokens_seen_global: 1425408000, tokens_per_sec_global: 582825.5008189933, max_mem_mb: 47064.891904
[log] train loss: 4.9080281257629395, step: 15000, tokens_seen_global: 1474560000, tokens_per_sec_global: 582856.819680786, max_mem_mb: 47064.891904
[log] train loss: 5.03518533706665, step: 15500, tokens_seen_global: 1523712000, tokens_per_sec_global: 582863.8791942691, max_mem_mb: 47064.891904
[log] train loss: 4.970654487609863, step: 16000, tokens_seen_global: 1572864000, tokens_per_sec_global: 582875.2193052883, max_mem_mb: 47064.891904
[log] train loss: 4.947376728057861, step: 16500, tokens_seen_global: 1622016000, tokens_per_sec_global: 582880.7092964937, max_mem_mb: 47064.891904
[log] train loss: 4.941424369812012, step: 17000, tokens_seen_global: 1671168000, tokens_per_sec_global: 582907.872262392, max_mem_mb: 47064.891904
[log] train loss: 4.976890563964844, step: 17500, tokens_seen_global: 1720320000, tokens_per_sec_global: 582887.19365375, max_mem_mb: 47064.891904
[log] train loss: 4.980648517608643, step: 18000, tokens_seen_global: 1769472000, tokens_per_sec_global: 582921.1273166807, max_mem_mb: 47064.891904
[log] train loss: 5.032413005828857, step: 18500, tokens_seen_global: 1818624000, tokens_per_sec_global: 582937.7033404027, max_mem_mb: 47064.891904
[log] train loss: 5.054568767547607, step: 19000, tokens_seen_global: 1867776000, tokens_per_sec_global: 582942.6769132377, max_mem_mb: 47064.891904
[log] train loss: 5.109541416168213, step: 19500, tokens_seen_global: 1916928000, tokens_per_sec_global: 582938.4927389951, max_mem_mb: 47064.891904
[log] train loss: 5.0656280517578125, step: 20000, tokens_seen_global: 1966080000, tokens_per_sec_global: 582948.3133010353, max_mem_mb: 47064.891904
[log] train loss: 4.958222389221191, step: 20500, tokens_seen_global: 2015232000, tokens_per_sec_global: 582942.3976051067, max_mem_mb: 47064.891904
[log] train loss: 4.986871719360352, step: 21000, tokens_seen_global: 2064384000, tokens_per_sec_global: 582963.4077711238, max_mem_mb: 47064.891904
[log] train loss: 4.872625350952148, step: 21500, tokens_seen_global: 2113536000, tokens_per_sec_global: 582973.0269784522, max_mem_mb: 47064.891904
[log] train loss: 5.0016045570373535, step: 22000, tokens_seen_global: 2162688000, tokens_per_sec_global: 582991.1432137429, max_mem_mb: 47064.891904
[log] train loss: 4.95646858215332, step: 22500, tokens_seen_global: 2211840000, tokens_per_sec_global: 582977.8882668333, max_mem_mb: 47064.891904
[log] train loss: 4.92991828918457, step: 23000, tokens_seen_global: 2260992000, tokens_per_sec_global: 583004.692638988, max_mem_mb: 47064.891904
[log] train loss: 4.881126403808594, step: 23500, tokens_seen_global: 2310144000, tokens_per_sec_global: 583000.6688118869, max_mem_mb: 47064.891904
[log] train loss: 4.927186012268066, step: 24000, tokens_seen_global: 2359296000, tokens_per_sec_global: 583004.9267955392, max_mem_mb: 47064.891904
[log] train loss: 4.989944934844971, step: 24500, tokens_seen_global: 2408448000, tokens_per_sec_global: 582986.005812833, max_mem_mb: 47064.891904
[log] train loss: 4.912851333618164, step: 25000, tokens_seen_global: 2457600000, tokens_per_sec_global: 583008.4841364673, max_mem_mb: 47064.891904
[log] train loss: 4.945506572723389, step: 25500, tokens_seen_global: 2506752000, tokens_per_sec_global: 583011.0511963732, max_mem_mb: 47064.891904
[log] train loss: 4.996039390563965, step: 26000, tokens_seen_global: 2555904000, tokens_per_sec_global: 583033.7120085977, max_mem_mb: 47064.891904
[log] train loss: 4.983078956604004, step: 26500, tokens_seen_global: 2605056000, tokens_per_sec_global: 583043.687827862, max_mem_mb: 47064.891904
[log] train loss: 4.919949054718018, step: 27000, tokens_seen_global: 2654208000, tokens_per_sec_global: 583064.4346065039, max_mem_mb: 47064.891904
[log] train loss: 5.020852565765381, step: 27500, tokens_seen_global: 2703360000, tokens_per_sec_global: 583047.149462825, max_mem_mb: 47064.891904
[log] train loss: 4.936343193054199, step: 28000, tokens_seen_global: 2752512000, tokens_per_sec_global: 583057.1453447723, max_mem_mb: 47064.891904
[log] train loss: 4.966063976287842, step: 28500, tokens_seen_global: 2801664000, tokens_per_sec_global: 583045.0174621684, max_mem_mb: 47064.891904
[log] train loss: 4.776083946228027, step: 29000, tokens_seen_global: 2850816000, tokens_per_sec_global: 583055.6023928433, max_mem_mb: 47064.891904
[log] train loss: 4.861738204956055, step: 29500, tokens_seen_global: 2899968000, tokens_per_sec_global: 583042.8183132295, max_mem_mb: 47064.891904
[log] train loss: 4.944642543792725, step: 30000, tokens_seen_global: 2949120000, tokens_per_sec_global: 583039.8059698435, max_mem_mb: 47064.891904
[log] train loss: 4.7279181480407715, step: 30500, tokens_seen_global: 2998272000, tokens_per_sec_global: 583022.3970351071, max_mem_mb: 47064.891904
[log] train loss: 4.899840354919434, step: 31000, tokens_seen_global: 3047424000, tokens_per_sec_global: 583029.2043682005, max_mem_mb: 47064.891904
[log] train loss: 4.925116062164307, step: 31500, tokens_seen_global: 3096576000, tokens_per_sec_global: 583025.6629990756, max_mem_mb: 47064.891904
[log] train loss: 4.62982177734375, step: 32000, tokens_seen_global: 3145728000, tokens_per_sec_global: 583039.5589280919, max_mem_mb: 47064.891904
[log] train loss: 4.769954204559326, step: 32500, tokens_seen_global: 3194880000, tokens_per_sec_global: 583038.1863259187, max_mem_mb: 47064.891904
[log] train loss: 4.814201831817627, step: 33000, tokens_seen_global: 3244032000, tokens_per_sec_global: 583050.5805084995, max_mem_mb: 47064.891904
[log] train loss: 4.89077091217041, step: 33500, tokens_seen_global: 3293184000, tokens_per_sec_global: 583055.3140750661, max_mem_mb: 47064.891904
[log] train loss: 4.774652481079102, step: 34000, tokens_seen_global: 3342336000, tokens_per_sec_global: 583064.6101946173, max_mem_mb: 47064.891904
[log] train loss: 4.917232990264893, step: 34500, tokens_seen_global: 3391488000, tokens_per_sec_global: 583061.1082825076, max_mem_mb: 47064.891904
[log] train loss: 4.837624549865723, step: 35000, tokens_seen_global: 3440640000, tokens_per_sec_global: 583077.479813402, max_mem_mb: 47064.891904
[log] train loss: 5.0319695472717285, step: 35500, tokens_seen_global: 3489792000, tokens_per_sec_global: 583078.4411691662, max_mem_mb: 47064.891904
[log] train loss: 4.896151542663574, step: 36000, tokens_seen_global: 3538944000, tokens_per_sec_global: 583063.4402810227, max_mem_mb: 47064.891904
[log] train loss: 5.084300994873047, step: 36500, tokens_seen_global: 3588096000, tokens_per_sec_global: 583066.2290219048, max_mem_mb: 47064.891904
[log] train loss: 5.064724922180176, step: 37000, tokens_seen_global: 3637248000, tokens_per_sec_global: 583074.6736998094, max_mem_mb: 47064.891904
[log] train loss: 4.915745735168457, step: 37500, tokens_seen_global: 3686400000, tokens_per_sec_global: 583076.3265678304, max_mem_mb: 47064.891904
[log] train loss: 5.012568473815918, step: 38000, tokens_seen_global: 3735552000, tokens_per_sec_global: 583088.6367167206, max_mem_mb: 47064.891904
[log] train loss: 4.995530605316162, step: 38500, tokens_seen_global: 3784704000, tokens_per_sec_global: 583086.7857699976, max_mem_mb: 47064.891904
[log] train loss: 4.901155948638916, step: 39000, tokens_seen_global: 3833856000, tokens_per_sec_global: 583093.2293920066, max_mem_mb: 47064.891904
[log] train loss: 4.818048000335693, step: 39500, tokens_seen_global: 3883008000, tokens_per_sec_global: 583082.4998650297, max_mem_mb: 47064.891904
[log] train loss: 4.977020740509033, step: 40000, tokens_seen_global: 3932160000, tokens_per_sec_global: 583089.4769143779, max_mem_mb: 47064.891904
[log] train loss: 5.025779724121094, step: 40500, tokens_seen_global: 3981312000, tokens_per_sec_global: 583085.9684232145, max_mem_mb: 47064.891904
[log] train loss: 4.935447692871094, step: 41000, tokens_seen_global: 4030464000, tokens_per_sec_global: 583094.8283789356, max_mem_mb: 47064.891904
[log] train loss: 4.939940929412842, step: 41500, tokens_seen_global: 4079616000, tokens_per_sec_global: 583086.3556085338, max_mem_mb: 47064.891904
[log] train loss: 5.054666519165039, step: 42000, tokens_seen_global: 4128768000, tokens_per_sec_global: 583098.9815997815, max_mem_mb: 47064.891904
[log] train loss: 4.937236785888672, step: 42500, tokens_seen_global: 4177920000, tokens_per_sec_global: 583099.7866161534, max_mem_mb: 47064.891904
[log] train loss: 5.012461185455322, step: 43000, tokens_seen_global: 4227072000, tokens_per_sec_global: 583105.559340791, max_mem_mb: 47064.891904
[log] train loss: 4.877928256988525, step: 43500, tokens_seen_global: 4276224000, tokens_per_sec_global: 583092.6305252501, max_mem_mb: 47064.891904
[log] train loss: 4.773812294006348, step: 44000, tokens_seen_global: 4325376000, tokens_per_sec_global: 583103.3195327206, max_mem_mb: 47064.891904
[log] train loss: 4.942628860473633, step: 44500, tokens_seen_global: 4374528000, tokens_per_sec_global: 583105.8699047028, max_mem_mb: 47064.891904
[log] train loss: 4.8235931396484375, step: 45000, tokens_seen_global: 4423680000, tokens_per_sec_global: 583115.8409475269, max_mem_mb: 47064.891904
[log] train loss: 4.897103786468506, step: 45500, tokens_seen_global: 4472832000, tokens_per_sec_global: 583116.4441045166, max_mem_mb: 47064.891904
[log] train loss: 4.944393157958984, step: 46000, tokens_seen_global: 4521984000, tokens_per_sec_global: 583128.2492730593, max_mem_mb: 47064.891904
[log] train loss: 4.918531894683838, step: 46500, tokens_seen_global: 4571136000, tokens_per_sec_global: 583131.2131315329, max_mem_mb: 47064.891904
[log] train loss: 4.8540167808532715, step: 47000, tokens_seen_global: 4620288000, tokens_per_sec_global: 583140.1169189274, max_mem_mb: 47064.891904
[log] train loss: 4.930497646331787, step: 47500, tokens_seen_global: 4669440000, tokens_per_sec_global: 583142.1559395689, max_mem_mb: 47064.891904
[log] train loss: 4.886422157287598, step: 48000, tokens_seen_global: 4718592000, tokens_per_sec_global: 583151.6229596481, max_mem_mb: 47064.891904
[log] train loss: 4.674021244049072, step: 48500, tokens_seen_global: 4767744000, tokens_per_sec_global: 583147.2640317832, max_mem_mb: 47064.891904
[log] train loss: 4.933821201324463, step: 49000, tokens_seen_global: 4816896000, tokens_per_sec_global: 583159.3567424073, max_mem_mb: 47064.891904
[log] train loss: 4.905229091644287, step: 49500, tokens_seen_global: 4866048000, tokens_per_sec_global: 583162.610157835, max_mem_mb: 47064.891904
[log] train loss: 4.969491481781006, step: 50000, tokens_seen_global: 4915200000, tokens_per_sec_global: 583174.4413555387, max_mem_mb: 47064.891904
[log] train loss: 4.751562118530273, step: 50500, tokens_seen_global: 4964352000, tokens_per_sec_global: 583176.8633561531, max_mem_mb: 47064.891904
[log] train loss: 4.978587627410889, step: 51000, tokens_seen_global: 5013504000, tokens_per_sec_global: 583187.1868114899, max_mem_mb: 47064.891904
[log] train loss: 5.074459552764893, step: 51500, tokens_seen_global: 5062656000, tokens_per_sec_global: 583180.4433284642, max_mem_mb: 47064.891904
[log] train loss: 4.839370250701904, step: 52000, tokens_seen_global: 5111808000, tokens_per_sec_global: 583187.9904198302, max_mem_mb: 47064.891904
[log] train loss: 4.959637641906738, step: 52500, tokens_seen_global: 5160960000, tokens_per_sec_global: 583186.0652906653, max_mem_mb: 47064.891904
[log] train loss: 4.985978603363037, step: 53000, tokens_seen_global: 5210112000, tokens_per_sec_global: 583191.6661374327, max_mem_mb: 47064.891904
[log] train loss: 5.074905872344971, step: 53500, tokens_seen_global: 5259264000, tokens_per_sec_global: 583187.2375781831, max_mem_mb: 47064.891904
[log] train loss: 4.831477165222168, step: 54000, tokens_seen_global: 5308416000, tokens_per_sec_global: 583195.2817275398, max_mem_mb: 47064.891904
[log] train loss: 5.1791229248046875, step: 54500, tokens_seen_global: 5357568000, tokens_per_sec_global: 583189.9208984594, max_mem_mb: 47064.891904
[log] train loss: 4.9791741371154785, step: 55000, tokens_seen_global: 5406720000, tokens_per_sec_global: 583200.3775360868, max_mem_mb: 47064.891904
[log] train loss: 4.825833797454834, step: 55500, tokens_seen_global: 5455872000, tokens_per_sec_global: 583194.8178242014, max_mem_mb: 47064.891904
[log] train loss: 5.094138145446777, step: 56000, tokens_seen_global: 5505024000, tokens_per_sec_global: 583203.5007020923, max_mem_mb: 47064.891904
[log] train loss: 4.801102161407471, step: 56500, tokens_seen_global: 5554176000, tokens_per_sec_global: 583193.071392094, max_mem_mb: 47064.891904
[log] train loss: 4.884799480438232, step: 57000, tokens_seen_global: 5603328000, tokens_per_sec_global: 583199.4311309155, max_mem_mb: 47064.891904
[log] train loss: 5.027064800262451, step: 57500, tokens_seen_global: 5652480000, tokens_per_sec_global: 583200.8885955147, max_mem_mb: 47064.891904
[log] train loss: 4.913793087005615, step: 58000, tokens_seen_global: 5701632000, tokens_per_sec_global: 583210.1569925465, max_mem_mb: 47064.891904
[log] train loss: 4.674255847930908, step: 58500, tokens_seen_global: 5750784000, tokens_per_sec_global: 583213.3807293477, max_mem_mb: 47064.891904
[log] train loss: 4.7385358810424805, step: 59000, tokens_seen_global: 5799936000, tokens_per_sec_global: 583222.6553936095, max_mem_mb: 47064.891904
[log] train loss: 4.7811384201049805, step: 59500, tokens_seen_global: 5849088000, tokens_per_sec_global: 583222.8598627582, max_mem_mb: 47064.891904
[log] train loss: 4.700143814086914, step: 60000, tokens_seen_global: 5898240000, tokens_per_sec_global: 583232.5493225477, max_mem_mb: 47064.891904
[log] train loss: 4.755130767822266, step: 60500, tokens_seen_global: 5947392000, tokens_per_sec_global: 583224.6724477031, max_mem_mb: 47064.891904
[log] train loss: 4.8398118019104, step: 61000, tokens_seen_global: 5996544000, tokens_per_sec_global: 583229.6277294848, max_mem_mb: 47064.891904
[log] train loss: 4.8961381912231445, step: 61500, tokens_seen_global: 6045696000, tokens_per_sec_global: 583226.9925036845, max_mem_mb: 47064.891904
[log] train loss: 4.812123775482178, step: 62000, tokens_seen_global: 6094848000, tokens_per_sec_global: 583229.7314344366, max_mem_mb: 47064.891904
[log] train loss: 4.767185688018799, step: 62500, tokens_seen_global: 6144000000, tokens_per_sec_global: 583222.4406611135, max_mem_mb: 47064.891904
[log] train loss: 4.92100715637207, step: 63000, tokens_seen_global: 6193152000, tokens_per_sec_global: 583225.3391467129, max_mem_mb: 47064.891904
[log] train loss: 4.930916786193848, step: 63500, tokens_seen_global: 6242304000, tokens_per_sec_global: 583227.3794126475, max_mem_mb: 47064.891904
[log] train loss: 4.750178337097168, step: 64000, tokens_seen_global: 6291456000, tokens_per_sec_global: 583233.3045095261, max_mem_mb: 47064.891904
[log] train loss: 4.8908538818359375, step: 64500, tokens_seen_global: 6340608000, tokens_per_sec_global: 583225.2773389425, max_mem_mb: 47064.891904
[log] train loss: 4.6952009201049805, step: 65000, tokens_seen_global: 6389760000, tokens_per_sec_global: 583227.1461832548, max_mem_mb: 47064.891904
[log] train loss: 4.817866802215576, step: 65500, tokens_seen_global: 6438912000, tokens_per_sec_global: 583229.8727839933, max_mem_mb: 47064.891904
[log] train loss: 4.949194431304932, step: 66000, tokens_seen_global: 6488064000, tokens_per_sec_global: 583234.5549223501, max_mem_mb: 47064.891904
[log] train loss: 4.869938373565674, step: 66500, tokens_seen_global: 6537216000, tokens_per_sec_global: 583227.05884704, max_mem_mb: 47064.891904
[log] train loss: 4.681183338165283, step: 67000, tokens_seen_global: 6586368000, tokens_per_sec_global: 583230.2195934531, max_mem_mb: 47064.891904
[log] train loss: 5.023970603942871, step: 67500, tokens_seen_global: 6635520000, tokens_per_sec_global: 583229.2575905479, max_mem_mb: 47064.891904
[log] train loss: 4.866593360900879, step: 68000, tokens_seen_global: 6684672000, tokens_per_sec_global: 583228.2769568248, max_mem_mb: 47064.891904
[log] train loss: 4.646869659423828, step: 68500, tokens_seen_global: 6733824000, tokens_per_sec_global: 583221.9720561715, max_mem_mb: 47064.891904
[log] train loss: 4.912475109100342, step: 69000, tokens_seen_global: 6782976000, tokens_per_sec_global: 583227.32950512, max_mem_mb: 47064.891904
[log] train loss: 4.885189533233643, step: 69500, tokens_seen_global: 6832128000, tokens_per_sec_global: 583222.3444019549, max_mem_mb: 47064.891904
[log] train loss: 4.80053186416626, step: 70000, tokens_seen_global: 6881280000, tokens_per_sec_global: 583222.4818605139, max_mem_mb: 47064.891904
[log] train loss: 4.771298885345459, step: 70500, tokens_seen_global: 6930432000, tokens_per_sec_global: 583221.5722467058, max_mem_mb: 47064.891904
[log] train loss: 4.755009651184082, step: 71000, tokens_seen_global: 6979584000, tokens_per_sec_global: 583221.8304680263, max_mem_mb: 47064.891904
[log] train loss: 4.75792932510376, step: 71500, tokens_seen_global: 7028736000, tokens_per_sec_global: 583224.3566435357, max_mem_mb: 47064.891904
[log] train loss: 4.787140846252441, step: 72000, tokens_seen_global: 7077888000, tokens_per_sec_global: 583225.5025805326, max_mem_mb: 47064.891904
[log] train loss: 4.882577896118164, step: 72500, tokens_seen_global: 7127040000, tokens_per_sec_global: 583219.5942733865, max_mem_mb: 47064.891904
[log] train loss: 4.769065856933594, step: 73000, tokens_seen_global: 7176192000, tokens_per_sec_global: 583227.377838409, max_mem_mb: 47064.891904
[log] train loss: 4.835448741912842, step: 73500, tokens_seen_global: 7225344000, tokens_per_sec_global: 583230.338787725, max_mem_mb: 47064.891904
[log] train loss: 4.867859840393066, step: 74000, tokens_seen_global: 7274496000, tokens_per_sec_global: 583238.7954943734, max_mem_mb: 47064.891904
[log] train loss: 5.028441905975342, step: 74500, tokens_seen_global: 7323648000, tokens_per_sec_global: 583235.8407620302, max_mem_mb: 47064.891904
[log] train loss: 4.8486480712890625, step: 75000, tokens_seen_global: 7372800000, tokens_per_sec_global: 583245.2463920465, max_mem_mb: 47064.891904
[log] train loss: 4.8764729499816895, step: 75500, tokens_seen_global: 7421952000, tokens_per_sec_global: 583244.4383483394, max_mem_mb: 47064.891904
[log] train loss: 4.790375232696533, step: 76000, tokens_seen_global: 7471104000, tokens_per_sec_global: 583249.1304694914, max_mem_mb: 47064.891904
[log] train loss: 4.945710182189941, step: 76500, tokens_seen_global: 7520256000, tokens_per_sec_global: 583244.6917098367, max_mem_mb: 47064.891904
[log] train loss: 4.965674877166748, step: 77000, tokens_seen_global: 7569408000, tokens_per_sec_global: 583247.1263210203, max_mem_mb: 47064.891904
[log] train loss: 4.792921543121338, step: 77500, tokens_seen_global: 7618560000, tokens_per_sec_global: 583250.0233410296, max_mem_mb: 47064.891904
[log] train loss: 4.836769104003906, step: 78000, tokens_seen_global: 7667712000, tokens_per_sec_global: 583256.4001385029, max_mem_mb: 47064.891904
[log] train loss: 4.833250999450684, step: 78500, tokens_seen_global: 7716864000, tokens_per_sec_global: 583256.1178632086, max_mem_mb: 47064.891904
[log] train loss: 4.661313533782959, step: 79000, tokens_seen_global: 7766016000, tokens_per_sec_global: 583261.7402280178, max_mem_mb: 47064.891904
[log] train loss: 4.751405239105225, step: 79500, tokens_seen_global: 7815168000, tokens_per_sec_global: 583261.2031279239, max_mem_mb: 47064.891904
[log] train loss: 5.103453636169434, step: 80000, tokens_seen_global: 7864320000, tokens_per_sec_global: 583266.7547037667, max_mem_mb: 47064.891904
[log] train loss: 4.779847145080566, step: 80500, tokens_seen_global: 7913472000, tokens_per_sec_global: 583268.1489135379, max_mem_mb: 47064.891904
[log] train loss: 4.719727039337158, step: 81000, tokens_seen_global: 7962624000, tokens_per_sec_global: 583274.8639463653, max_mem_mb: 47064.891904
[log] train loss: 5.032094478607178, step: 81500, tokens_seen_global: 8011776000, tokens_per_sec_global: 583277.0093916657, max_mem_mb: 47064.891904
[log] train loss: 4.779323101043701, step: 82000, tokens_seen_global: 8060928000, tokens_per_sec_global: 583281.2123777542, max_mem_mb: 47064.891904
[log] train loss: 4.908966064453125, step: 82500, tokens_seen_global: 8110080000, tokens_per_sec_global: 583273.1248616766, max_mem_mb: 47064.891904
[log] train loss: 4.95689582824707, step: 83000, tokens_seen_global: 8159232000, tokens_per_sec_global: 583277.4712559128, max_mem_mb: 47064.891904
[log] train loss: 4.728753089904785, step: 83500, tokens_seen_global: 8208384000, tokens_per_sec_global: 583271.2958474413, max_mem_mb: 47064.891904
[log] train loss: 4.709240913391113, step: 84000, tokens_seen_global: 8257536000, tokens_per_sec_global: 583272.549554596, max_mem_mb: 47064.891904
[log] train loss: 5.0238752365112305, step: 84500, tokens_seen_global: 8306688000, tokens_per_sec_global: 583271.2995267571, max_mem_mb: 47064.891904
[log] train loss: 4.878440856933594, step: 85000, tokens_seen_global: 8355840000, tokens_per_sec_global: 583276.5552434408, max_mem_mb: 47064.891904
[log] train loss: 4.719479084014893, step: 85500, tokens_seen_global: 8404992000, tokens_per_sec_global: 583275.9992889137, max_mem_mb: 47064.891904
[log] train loss: 4.870352745056152, step: 86000, tokens_seen_global: 8454144000, tokens_per_sec_global: 583283.0562536757, max_mem_mb: 47064.891904
[log] train loss: 4.834578514099121, step: 86500, tokens_seen_global: 8503296000, tokens_per_sec_global: 583277.5274957245, max_mem_mb: 47064.891904
[log] train loss: 4.799666881561279, step: 87000, tokens_seen_global: 8552448000, tokens_per_sec_global: 583284.4929956364, max_mem_mb: 47064.891904
[log] train loss: 4.790830135345459, step: 87500, tokens_seen_global: 8601600000, tokens_per_sec_global: 583286.3906194577, max_mem_mb: 47064.891904
[log] train loss: 4.930108547210693, step: 88000, tokens_seen_global: 8650752000, tokens_per_sec_global: 583292.0231481575, max_mem_mb: 47064.891904
[log] train loss: 4.898561954498291, step: 88500, tokens_seen_global: 8699904000, tokens_per_sec_global: 583289.9961712318, max_mem_mb: 47064.891904
[log] train loss: 4.863464832305908, step: 89000, tokens_seen_global: 8749056000, tokens_per_sec_global: 583293.4014737022, max_mem_mb: 47064.891904
[log] train loss: 4.8265581130981445, step: 89500, tokens_seen_global: 8798208000, tokens_per_sec_global: 583295.9040733252, max_mem_mb: 47064.891904
[log] train loss: 4.885881423950195, step: 90000, tokens_seen_global: 8847360000, tokens_per_sec_global: 583298.1047616313, max_mem_mb: 47064.891904
[log] train loss: 4.8131632804870605, step: 90500, tokens_seen_global: 8896512000, tokens_per_sec_global: 583297.6712668635, max_mem_mb: 47064.891904
[log] train loss: 4.999721050262451, step: 91000, tokens_seen_global: 8945664000, tokens_per_sec_global: 583304.5051276798, max_mem_mb: 47064.891904
[log] train loss: 4.927402973175049, step: 91500, tokens_seen_global: 8994816000, tokens_per_sec_global: 583307.1857823693, max_mem_mb: 47064.891904
[log] train loss: 5.082874774932861, step: 92000, tokens_seen_global: 9043968000, tokens_per_sec_global: 583314.2069635617, max_mem_mb: 47064.891904
[log] train loss: 4.846045970916748, step: 92500, tokens_seen_global: 9093120000, tokens_per_sec_global: 583311.0598008686, max_mem_mb: 47064.891904
[log] train loss: 4.864633560180664, step: 93000, tokens_seen_global: 9142272000, tokens_per_sec_global: 583311.2119233662, max_mem_mb: 47064.891904
[log] train loss: 4.8569111824035645, step: 93500, tokens_seen_global: 9191424000, tokens_per_sec_global: 583313.215851462, max_mem_mb: 47064.891904
[log] train loss: 4.883905410766602, step: 94000, tokens_seen_global: 9240576000, tokens_per_sec_global: 583311.7389516569, max_mem_mb: 47064.891904
[log] train loss: 4.809321880340576, step: 94500, tokens_seen_global: 9289728000, tokens_per_sec_global: 583311.5668454916, max_mem_mb: 47064.891904
[log] train loss: 4.668445110321045, step: 95000, tokens_seen_global: 9338880000, tokens_per_sec_global: 583309.7687176397, max_mem_mb: 47064.891904
[log] train loss: 4.6382856369018555, step: 95500, tokens_seen_global: 9388032000, tokens_per_sec_global: 583302.8635517135, max_mem_mb: 47064.891904
[log] train loss: 4.772696495056152, step: 96000, tokens_seen_global: 9437184000, tokens_per_sec_global: 583309.1483378048, max_mem_mb: 47064.891904
[log] train loss: 4.65675163269043, step: 96500, tokens_seen_global: 9486336000, tokens_per_sec_global: 583309.4241983835, max_mem_mb: 47064.891904
[log] train loss: 5.011048793792725, step: 97000, tokens_seen_global: 9535488000, tokens_per_sec_global: 583309.1511954799, max_mem_mb: 47064.891904
[log] train loss: 4.894917011260986, step: 97500, tokens_seen_global: 9584640000, tokens_per_sec_global: 583310.14479879, max_mem_mb: 47064.891904
[log] train loss: 4.6091718673706055, step: 98000, tokens_seen_global: 9633792000, tokens_per_sec_global: 583312.8287877274, max_mem_mb: 47064.891904
[log] train loss: 4.920985221862793, step: 98500, tokens_seen_global: 9682944000, tokens_per_sec_global: 583314.6919905127, max_mem_mb: 47064.891904
[log] train loss: 5.098648548126221, step: 99000, tokens_seen_global: 9732096000, tokens_per_sec_global: 583318.9235818262, max_mem_mb: 47064.891904
[log] train loss: 4.761599540710449, step: 99500, tokens_seen_global: 9781248000, tokens_per_sec_global: 583314.1958424998, max_mem_mb: 47064.891904
[log] train loss: 4.96479606628418, step: 100000, tokens_seen_global: 9830400000, tokens_per_sec_global: 583319.0693805218, max_mem_mb: 47064.891904
[log] train loss: 4.816768169403076, step: 100500, tokens_seen_global: 9879552000, tokens_per_sec_global: 583314.0554663661, max_mem_mb: 47064.891904
[log] train loss: 4.901707172393799, step: 101000, tokens_seen_global: 9928704000, tokens_per_sec_global: 583318.7768097112, max_mem_mb: 47064.891904
[log] train loss: 5.080084800720215, step: 101500, tokens_seen_global: 9977856000, tokens_per_sec_global: 583318.8503506796, max_mem_mb: 47064.891904
HF upload skipped (token absent or repo not specified).
‚ñ∂Ô∏è babylm „ÉÜ„Çπ„Éà„Çª„ÉÉ„Éà„Åß mean-so-far-PPL „ÇíÊúÄÂ§ß 4096 „Éà„Éº„ÇØ„É≥„Åæ„ÅßË®àÊ∏¨„Åó„Åæ„Åô‚Ä¶
Computing mean-so-far PPL:   0%|          | 0/100 [00:00<?, ?it/s]Computing mean-so-far PPL:   1%|          | 1/100 [00:00<00:11,  8.26it/s]Computing mean-so-far PPL:   3%|‚ñé         | 3/100 [00:00<00:09, 10.08it/s]Computing mean-so-far PPL:   5%|‚ñå         | 5/100 [00:00<00:09, 10.54it/s]Computing mean-so-far PPL:   7%|‚ñã         | 7/100 [00:00<00:08, 10.72it/s]Computing mean-so-far PPL:   9%|‚ñâ         | 9/100 [00:00<00:08, 10.81it/s]Computing mean-so-far PPL:  11%|‚ñà         | 11/100 [00:01<00:08, 10.81it/s]Computing mean-so-far PPL:  13%|‚ñà‚ñé        | 13/100 [00:01<00:07, 10.88it/s]Computing mean-so-far PPL:  15%|‚ñà‚ñå        | 15/100 [00:01<00:07, 10.83it/s]Computing mean-so-far PPL:  17%|‚ñà‚ñã        | 17/100 [00:01<00:07, 10.88it/s]Computing mean-so-far PPL:  19%|‚ñà‚ñâ        | 19/100 [00:01<00:07, 10.86it/s]Computing mean-so-far PPL:  21%|‚ñà‚ñà        | 21/100 [00:01<00:07, 10.98it/s]Computing mean-so-far PPL:  23%|‚ñà‚ñà‚ñé       | 23/100 [00:02<00:06, 11.06it/s]Computing mean-so-far PPL:  25%|‚ñà‚ñà‚ñå       | 25/100 [00:02<00:06, 11.09it/s]Computing mean-so-far PPL:  27%|‚ñà‚ñà‚ñã       | 27/100 [00:02<00:06, 11.13it/s]Computing mean-so-far PPL:  29%|‚ñà‚ñà‚ñâ       | 29/100 [00:02<00:06, 11.20it/s]Computing mean-so-far PPL:  31%|‚ñà‚ñà‚ñà       | 31/100 [00:02<00:06, 11.24it/s]Computing mean-so-far PPL:  33%|‚ñà‚ñà‚ñà‚ñé      | 33/100 [00:03<00:05, 11.24it/s]Computing mean-so-far PPL:  35%|‚ñà‚ñà‚ñà‚ñå      | 35/100 [00:03<00:05, 11.23it/s]Computing mean-so-far PPL:  37%|‚ñà‚ñà‚ñà‚ñã      | 37/100 [00:03<00:05, 11.25it/s]Computing mean-so-far PPL:  39%|‚ñà‚ñà‚ñà‚ñâ      | 39/100 [00:03<00:05, 11.28it/s]Computing mean-so-far PPL:  41%|‚ñà‚ñà‚ñà‚ñà      | 41/100 [00:03<00:05, 11.25it/s]Computing mean-so-far PPL:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 43/100 [00:03<00:05, 11.21it/s]Computing mean-so-far PPL:  45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 45/100 [00:04<00:04, 11.26it/s]Computing mean-so-far PPL:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 47/100 [00:04<00:04, 11.27it/s]Computing mean-so-far PPL:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 49/100 [00:04<00:04, 11.27it/s]Computing mean-so-far PPL:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 51/100 [00:04<00:04, 11.27it/s]Computing mean-so-far PPL:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 53/100 [00:04<00:04, 11.22it/s]Computing mean-so-far PPL:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 55/100 [00:04<00:04, 11.21it/s]Computing mean-so-far PPL:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 57/100 [00:05<00:03, 11.24it/s]Computing mean-so-far PPL:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 59/100 [00:05<00:03, 11.28it/s]Computing mean-so-far PPL:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 61/100 [00:05<00:03, 11.28it/s]Computing mean-so-far PPL:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 63/100 [00:05<00:03, 11.33it/s]Computing mean-so-far PPL:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 65/100 [00:05<00:03, 11.30it/s]Computing mean-so-far PPL:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 67/100 [00:06<00:02, 11.23it/s]Computing mean-so-far PPL:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 69/100 [00:06<00:02, 11.27it/s]Computing mean-so-far PPL:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 71/100 [00:06<00:02, 11.23it/s]Computing mean-so-far PPL:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 73/100 [00:06<00:02, 11.26it/s]Computing mean-so-far PPL:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 75/100 [00:06<00:02, 11.29it/s]Computing mean-so-far PPL:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 77/100 [00:06<00:02, 11.32it/s]Computing mean-so-far PPL:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 79/100 [00:07<00:01, 11.32it/s]Computing mean-so-far PPL:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 81/100 [00:07<00:01, 11.34it/s]Computing mean-so-far PPL:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 83/100 [00:07<00:01, 10.61it/s]Computing mean-so-far PPL:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 85/100 [00:07<00:01, 10.77it/s]Computing mean-so-far PPL:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 87/100 [00:07<00:01, 10.89it/s]Computing mean-so-far PPL:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 89/100 [00:08<00:01, 10.97it/s]Computing mean-so-far PPL:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 91/100 [00:08<00:00, 11.10it/s]Computing mean-so-far PPL:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 93/100 [00:08<00:00, 11.13it/s]Computing mean-so-far PPL:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 95/100 [00:08<00:00, 11.18it/s]Computing mean-so-far PPL:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 97/100 [00:08<00:00, 11.23it/s]Computing mean-so-far PPL:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 99/100 [00:08<00:00, 11.22it/s]Computing mean-so-far PPL: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:08<00:00, 11.12it/s]
wandb: updating run metadata; uploading artifact run-4r9ewop2-mean_so_far_ppl_curve_table; uploading media/table/mean_so_far_ppl_curve_table_101727_89d1c9ea9cfb1552ff9f.table.json
wandb: uploading artifact run-4r9ewop2-mean_so_far_ppl_curve_table; uploading output.log; uploading wandb-summary.json; uploading config.yaml
wandb: uploading artifact run-4r9ewop2-mean_so_far_ppl_curve_table
wandb: 
wandb: Run history:
wandb:            current_lr ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:      inference_mem_MB ‚ñÅ
wandb:        inference_time ‚ñÅ
wandb: inference_tok_per_sec ‚ñÅ
wandb:            max_mem_mb ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:             max_steps ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:          seenedtokens ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb:   seenedtokens_global ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:                  step ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:        tokens_per_sec ‚ñÅ‚ñÖ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:                    +5 ...
wandb: 
wandb: Run summary:
wandb:            current_lr 0
wandb:      inference_mem_MB 8126.58483
wandb:        inference_time 9.00712
wandb: inference_tok_per_sec 45475.14298
wandb:            max_mem_mb 47064.8919
wandb:             max_steps 101726
wandb:          seenedtokens 10000072704
wandb:   seenedtokens_global 10000072704
wandb:                  step 101726
wandb:        tokens_per_sec 583318.14794
wandb:                    +5 ...
wandb: 
wandb: üöÄ View run NGRC_LM(113.51M_10BT_lr5e-4_d2048_poly1_bs198)3 at: https://wandb.ai/telutelu/NGRC_LanguageModel/runs/4r9ewop2
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/telutelu/NGRC_LanguageModel
wandb: Synced 5 W&B file(s), 102 media file(s), 2 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20251222_102518-4r9ewop2/logs
Inference time: 9.01s, Tokens/sec: 45475.14, Memory: 8126.58MB
üìÑ Training report written to ./reports_ngrc/NGRC_LM(113.51M_10BT_lr5e-4_d2048_poly1_bs198)3_report.txt
